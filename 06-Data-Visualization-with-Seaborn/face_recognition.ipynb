{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qiRarB8quRtk"
   },
   "source": [
    "Starting with face recognition and basics to see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uN76eTu7uY9z"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing all the libraries in one go.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import model_from_json\n",
    "from os import listdir\n",
    "import os\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJ5hBRmcueHN"
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_cascade.load('C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sECMgAI9uskX"
   },
   "outputs": [],
   "source": [
    "# Setting the present directory where all the files are available.\n",
    "os.chdir(\"D:\\Learning/Machine Learning Training\\PGP ML\\Capstone Project\\\\\")\n",
    "dir_path = \"D:\\Learning/Machine Learning Training\\PGP ML\\Capstone Project\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tgSGEqv1lP1"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(160, 160))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    #preprocess_input normalizes input in scale of [-1, +1]. You must apply same normalization in prediction.\n",
    "    #Ref: https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py (Line 45)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inception_resnet_v1 import *\n",
    "model = InceptionResNetV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cWnEPga42Lxt",
    "outputId": "b5ed794c-91e9-4a53-a06f-7c948105b949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights loaded\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('facenet_weights.h5')\n",
    "print(\"weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXnyQGTU55Qv"
   },
   "outputs": [],
   "source": [
    "# Finding Eucledian distance between 2 images\n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqoKoN1t7GFk"
   },
   "outputs": [],
   "source": [
    "threshold = 21 #tuned threshold for l2 disabled euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wV_nv4CH7M2N"
   },
   "outputs": [],
   "source": [
    "employee_pictures = \"D:\\Learning/Machine Learning Training\\PGP ML\\Capstone Project\\database\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SFeziKE8qGH"
   },
   "outputs": [],
   "source": [
    "employees = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UlT1S1uj8rAc",
    "outputId": "bbe1159f-2394-4b48-be2a-87ebae63fd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "for file in listdir(employee_pictures):\n",
    "\temployee, extension = file.split(\".\")\n",
    "\timg = preprocess_image('D:\\Learning/Machine Learning Training\\PGP ML\\Capstone Project\\database\\\\%s.jpeg' % (employee))\n",
    "\trepresentation = model.predict(img)[0,:]\n",
    "\t\n",
    "\temployees[employee] = representation\n",
    "\t\n",
    "print(\"employee representations retrieved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "btq3jfF6LrS8"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ret, img = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "4rMu0S7CLy7I",
    "outputId": "8fc16abc-f7e3-48f1-f907-d46ec95a8372"
   },
   "outputs": [],
   "source": [
    "while(True):\n",
    "  ret, img = cap.read()\n",
    "  #print(ret,img)\n",
    "  faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "  #faces = face_cascade.detectMultiScale('/content/drive/My Drive/Colab Notebooks/Capstone Project/new one/screenshot/photo.jpg', 1.3, 5)\n",
    "\t\n",
    "  for (x,y,w,h) in faces:\n",
    "    if w > 130: #discard small detected faces\n",
    "      cv2.rectangle(img, (x,y), (x+w,y+h), (67, 67, 67), 1) #draw rectangle to main image\n",
    "\t\t\t\n",
    "      detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "      detected_face = cv2.resize(detected_face, (160, 160)) #resize to 224x224\n",
    "\t\t\t\n",
    "      img_pixels = image.img_to_array(detected_face)\n",
    "      img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\t\t\t#employee dictionary is using preprocess_image and it normalizes in scale of [-1, +1]\n",
    "      img_pixels /= 127.5\n",
    "      img_pixels -= 1\n",
    "\t\t\t\n",
    "      captured_representation = model.predict(img_pixels)[0,:]\n",
    "\t\t\t\n",
    "      distances = []\n",
    "\t\t\t\n",
    "      for i in employees:\n",
    "        employee_name = i\n",
    "        source_representation = employees[i]\n",
    "\t\t\t\t\n",
    "        distance = findEuclideanDistance(captured_representation, source_representation)\n",
    "\t\t\t\t\n",
    "\t\t\t\t#print(employee_name,\": \",distance)\n",
    "        distances.append(distance)\n",
    "\t\t\t\n",
    "      label_name = 'unknown'\n",
    "      index = 0\n",
    "      for i in employees:\n",
    "        employee_name = i\n",
    "        if index == np.argmin(distances):\n",
    "          if distances[index] <= threshold:\n",
    "\t\t\t\t\t\t#print(\"detected: \",employee_name)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t#label_name = \"%s (distance: %s)\" % (employee_name, str(round(distance,2)))\n",
    "            similarity = 100 + (20 - distance)\n",
    "            if similarity > 99.99: similarity = 99.99\n",
    "\t\t\t\t\t\t\n",
    "            label_name = \"%s (%s%s)\" % (employee_name, str(round(similarity,2)), '%')\n",
    "\t\t\t\t\t\t\n",
    "            break\n",
    "\t\t\t\t#\t\n",
    "        index = index + 1\n",
    "\t\t\t\n",
    "      cv2.putText(img, label_name, (int(x+w+15), int(y-64)), cv2.FONT_HERSHEY_SIMPLEX, 1, (67,67,67), 2)\n",
    "\t\t\t\t\t\n",
    "\t\t\t#connect face and text\n",
    "      cv2.line(img,(x+w, y-64),(x+w-25, y-64),(67,67,67),1)\n",
    "      cv2.line(img,(int(x+w/2),y),(x+w-25,y-64),(67,67,67),1)\n",
    "\t\t\t\n",
    "  cv2.imshow('img',img)\n",
    "\t\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kill open cv thingsq\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "face_recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
